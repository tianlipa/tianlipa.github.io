<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="xnevF7kqEaJI7y45BmO0xpIUVUa0xusjcJ0MIFbvX2I">
  <meta name="msvalidate.01" content="0E006AA8DCC38A710D0287C1DD04DDCA">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css2?family=Lato:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.0/css/all.min.css" integrity="sha256-VHqXKFhhMxcpubYf9xiWdCiojEbY9NexQ4jh8AxbvcM=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"tianlipa.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.24.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":16,"offset":12},"hljswrap":true,"codeblock":{"theme":{"light":"default","dark":"stackoverflow-dark"},"prism":{"light":"prism","dark":"prism-dark"},"copy_button":{"enable":true,"style":null},"fold":{"enable":false,"height":500},"language":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeIn","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="GitHub链接 图片数据建模. 准备数据 cifar2数据集包含5000张飞机airplane照片和5000张机动车automobile照片, 任务目标是训练一个模型区分airplane和automobile两种图片. 在Pytorch中构建图片数据管道通常有两种方法:  使用torchvision中的datasets.ImageFolder读取图片, 然后用DataLoader并行加载 通过继">
<meta property="og:type" content="article">
<meta property="og:title" content="20天狂宴Pytorch-Day2">
<meta property="og:url" content="https://tianlipa.github.io/2025/08/eat-pytorch-2/index.html">
<meta property="og:site_name" content="tianlipa">
<meta property="og:description" content="GitHub链接 图片数据建模. 准备数据 cifar2数据集包含5000张飞机airplane照片和5000张机动车automobile照片, 任务目标是训练一个模型区分airplane和automobile两种图片. 在Pytorch中构建图片数据管道通常有两种方法:  使用torchvision中的datasets.ImageFolder读取图片, 然后用DataLoader并行加载 通过继">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://tianlipa.github.io/img/eat-pytorch-2/1.png">
<meta property="article:published_time" content="2025-08-27T03:42:35.000Z">
<meta property="article:modified_time" content="2025-08-30T01:24:41.031Z">
<meta property="article:author" content="tianlipa">
<meta property="article:tag" content="大模型">
<meta property="article:tag" content="pytorch">
<meta property="article:tag" content="USTC-MINE">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://tianlipa.github.io/img/eat-pytorch-2/1.png">


<link rel="canonical" href="https://tianlipa.github.io/2025/08/eat-pytorch-2/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://tianlipa.github.io/2025/08/eat-pytorch-2/","path":"2025/08/eat-pytorch-2/","title":"20天狂宴Pytorch-Day2"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>20天狂宴Pytorch-Day2 | tianlipa</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">false</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css" integrity="sha256-UF1fgpAiu3tPJN/uCqEUHNe7pnr+QR0SQDNfgglgtcM=" crossorigin="anonymous">



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">tianlipa</p>
      <i class="logo-line"></i>
    </a>
      <!-- <p class="site-subtitle" itemprop="description">Subtitle</p> -->
      <div id="randomParagraph" class="site-subtitle" itemprop="description"></div>
      <script src="/js/subtitle.js"></script>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-收藏"><a href="/collection/" rel="section"><i class="fa fa-heart fa-fw"></i>收藏</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">tianlipa</p>
  <div class="site-description" itemprop="description">本站所有内容<br>都是我家猫写的<br>如有任何疑问<br>喵喵喵喵喵喵喵</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">87</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/tianlipa" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;tianlipa" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:tianlipa@qq.com" title="E-Mail → mailto:tianlipa@qq.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://steamcommunity.com/id/tianlipa" title="Steam → https:&#x2F;&#x2F;steamcommunity.com&#x2F;id&#x2F;tianlipa" rel="noopener me" target="_blank"><i class="fab fa-steam fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/tianlipa" title="Zhihu → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;tianlipa" rel="noopener me" target="_blank"><i class="fab fa-zhihu fa-fw"></i></a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://tianlipa.github.io/2025/08/eat-pytorch-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="tianlipa">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="tianlipa">
      <meta itemprop="description" content="本站所有内容<br>都是我家猫写的<br>如有任何疑问<br>喵喵喵喵喵喵喵">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="20天狂宴Pytorch-Day2 | tianlipa">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          20天狂宴Pytorch-Day2
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-08-27 11:42:35" itemprop="dateCreated datePublished" datetime="2025-08-27T11:42:35+08:00">2025-08-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-08-30 09:24:41" itemprop="dateModified" datetime="2025-08-30T09:24:41+08:00">2025-08-30</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p><a target="_blank" rel="noopener" href="https://github.com/lyhue1991/eat_pytorch_in_20_days">GitHub链接</a></p>
<p>图片数据建模.</p>
<h2 id="准备数据">准备数据</h2>
<p>cifar2数据集包含5000张飞机airplane照片和5000张机动车automobile照片, 任务目标是训练一个模型区分airplane和automobile两种图片.</p>
<p>在Pytorch中构建图片数据管道通常有两种方法:</p>
<ul>
<li>使用torchvision中的datasets.ImageFolder读取图片, 然后用DataLoader并行加载</li>
<li>通过继承torch.utils.data.Dataset实现用户自定义读取逻辑, 然后用DataLoader并行加载</li>
</ul>
<p>本文介绍第一种方法.</p>
<span id="more"></span>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset,DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms <span class="keyword">as</span> T</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets </span><br><span class="line"></span><br><span class="line">transform_img = T.Compose(	<span class="comment"># 可以把多个图像处理步骤打包为一个流程, 如旋转裁切, 这里只有一步转换为tensor</span></span><br><span class="line">    [T.ToTensor()])	<span class="comment"># 把PIL图片或Numpy数组转换成tensor, 并把像素值压缩为[0, 1]的浮点数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">transform_label</span>(<span class="params">x</span>):	<span class="comment"># 处理标签, 把x转换为一维浮点数tensor</span></span><br><span class="line">    <span class="keyword">return</span> torch.tensor([x]).<span class="built_in">float</span>()</span><br></pre></td></tr></table></figure>
<p>ImageFolder是torchvision里最常用的数据集加载工具之一, 需要准备一个文件夹, 每个子文件夹的名字就是类别名, 如:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cifar2/train/</span><br><span class="line">    0_airplane/</span><br><span class="line">    1_automobile/</span><br><span class="line">cifar2/test/</span><br><span class="line">    0_airplane/</span><br><span class="line">    1_automobile/</span><br></pre></td></tr></table></figure>
<p>ImageFolder会自动扫描这些子文件夹, 给每个类别分配一个编号, 然后返回 (图像, 标签).</p>
<p>使用方法如下:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ds_train = datasets.ImageFolder(<span class="string">&quot;./eat_pytorch_datasets/cifar2/train/&quot;</span>,</span><br><span class="line">            transform = transform_img,target_transform = transform_label)</span><br><span class="line">ds_val = datasets.ImageFolder(<span class="string">&quot;./eat_pytorch_datasets/cifar2/test/&quot;</span>,</span><br><span class="line">            transform = transform_img,target_transform = transform_label)</span><br></pre></td></tr></table></figure>
<p>用DataLoader封装.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dl_train = DataLoader(ds_train,batch_size = <span class="number">50</span>,shuffle = <span class="literal">True</span>)</span><br><span class="line">dl_val = DataLoader(ds_val,batch_size = <span class="number">50</span>,shuffle = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>可以运行如下代码查看部分样本和shape.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt </span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">8</span>)) </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">9</span>):</span><br><span class="line">    img,label = ds_train[i]</span><br><span class="line">    img = img.permute(<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>)</span><br><span class="line">    ax=plt.subplot(<span class="number">3</span>,<span class="number">3</span>,i+<span class="number">1</span>)</span><br><span class="line">    ax.imshow(img.numpy())</span><br><span class="line">    ax.set_title(<span class="string">&quot;label = %d&quot;</span>%label.item())</span><br><span class="line">    ax.set_xticks([])</span><br><span class="line">    ax.set_yticks([]) </span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> features,labels <span class="keyword">in</span> dl_train:</span><br><span class="line">    <span class="built_in">print</span>(features.shape,labels.shape) </span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p><img src="/img/eat-pytorch-2/1.png" alt=""></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.Size([50, 3, 32, 32]) torch.Size([50, 1])</span><br></pre></td></tr></table></figure>
<p>Pytorch的图片默认顺序是Batch, Channel, Width, Height.</p>
<h2 id="建立模型">建立模型</h2>
<p>Pytorch通常有三种方式构建模型: 使用nn.Sequential按层顺序构建模型, 继承nn.Module基类构建自定义模型, 继承nn.Module基类构建模型并辅助应用模型容器进行封装, 此处选用继承nn.Module基类构建自定义模型.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(in_channels=<span class="number">3</span>,out_channels=<span class="number">32</span>,kernel_size = <span class="number">3</span>)</span><br><span class="line">        <span class="variable language_">self</span>.pool = nn.MaxPool2d(kernel_size = <span class="number">2</span>,stride = <span class="number">2</span>)</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(in_channels=<span class="number">32</span>,out_channels=<span class="number">64</span>,kernel_size = <span class="number">5</span>)</span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout2d(p = <span class="number">0.1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.adaptive_pool = nn.AdaptiveMaxPool2d((<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">        <span class="variable language_">self</span>.flatten = nn.Flatten()</span><br><span class="line">        <span class="variable language_">self</span>.linear1 = nn.Linear(<span class="number">64</span>,<span class="number">32</span>)</span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU()</span><br><span class="line">        <span class="variable language_">self</span>.linear2 = nn.Linear(<span class="number">32</span>,<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.pool(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv2(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.pool(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.dropout(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.adaptive_pool(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.flatten(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.linear1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.relu(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.linear2(x)</span><br><span class="line">        <span class="keyword">return</span> x </span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line"><span class="built_in">print</span>(net)</span><br></pre></td></tr></table></figure>
<p>Conv2d: 二维卷积层, 把图片通过一组filter变换成新的多通道特征.</p>
<p>MaxPool2d: 池化层, 压缩图片数据, 保留重要信息.</p>
<p>Dropout2d: 丢弃层, 随机遮挡一部分数据, 迫使网络不过度依赖某几个通道, 而是学会更普遍的特征.</p>
<p>ReLu: 激活函数.</p>
<p>可以利用<code>torchkeras.summary(net, input_data = features)</code>总结网络结构, 输出如下.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">--------------------------------------------------------------------------</span><br><span class="line">Layer (type)                            Output Shape              Param #</span><br><span class="line">==========================================================================</span><br><span class="line">Conv2d-1                            [-1, 32, 30, 30]                  896</span><br><span class="line">MaxPool2d-2                         [-1, 32, 15, 15]                    0</span><br><span class="line">Conv2d-3                            [-1, 64, 11, 11]               51,264</span><br><span class="line">MaxPool2d-4                           [-1, 64, 5, 5]                    0</span><br><span class="line">Dropout2d-5                           [-1, 64, 5, 5]                    0</span><br><span class="line">AdaptiveMaxPool2d-6                   [-1, 64, 1, 1]                    0</span><br><span class="line">Flatten-7                                   [-1, 64]                    0</span><br><span class="line">Linear-8                                    [-1, 32]                2,080</span><br><span class="line">ReLU-9                                      [-1, 32]                    0</span><br><span class="line">Linear-10                                    [-1, 1]                   33</span><br><span class="line">==========================================================================</span><br><span class="line">Total params: 54,273</span><br><span class="line">Trainable params: 54,273</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">--------------------------------------------------------------------------</span><br><span class="line">Input size (MB): 0.000076</span><br><span class="line">Forward/backward pass size (MB): 0.359627</span><br><span class="line">Params size (MB): 0.207035</span><br><span class="line">Estimated Total Size (MB): 0.566738</span><br><span class="line">--------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>
<h2 id="训练模型">训练模型</h2>
<p>和上次一样用仿照Keras风格的训练循环.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os,sys,time</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> datetime </span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn </span><br><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">printlog</span>(<span class="params">info</span>):</span><br><span class="line">    nowtime = datetime.datetime.now().strftime(<span class="string">&#x27;%Y-%m-%d %H:%M:%S&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>+<span class="string">&quot;==========&quot;</span>*<span class="number">8</span> + <span class="string">&quot;%s&quot;</span>%nowtime)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">str</span>(info)+<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">StepRunner</span>:	<span class="comment"># 一个batch</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, net, loss_fn,</span></span><br><span class="line"><span class="params">                 stage = <span class="string">&quot;train&quot;</span>, metrics_dict = <span class="literal">None</span>, </span></span><br><span class="line"><span class="params">                 optimizer = <span class="literal">None</span></span></span><br><span class="line"><span class="params">                 </span>):</span><br><span class="line">        <span class="variable language_">self</span>.net,<span class="variable language_">self</span>.loss_fn,<span class="variable language_">self</span>.metrics_dict,<span class="variable language_">self</span>.stage = net,loss_fn,metrics_dict,stage</span><br><span class="line">        <span class="variable language_">self</span>.optimizer = optimizer</span><br><span class="line">            </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">step</span>(<span class="params">self, features, labels</span>):</span><br><span class="line">        <span class="comment"># loss</span></span><br><span class="line">        preds = <span class="variable language_">self</span>.net(features)</span><br><span class="line">        loss = <span class="variable language_">self</span>.loss_fn(preds,labels)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># backward()</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.optimizer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="variable language_">self</span>.stage==<span class="string">&quot;train&quot;</span>: </span><br><span class="line">            loss.backward()	<span class="comment"># 计算每个权重的梯度</span></span><br><span class="line">            <span class="variable language_">self</span>.optimizer.step()	<span class="comment"># 根据梯度更新权重</span></span><br><span class="line">            <span class="variable language_">self</span>.optimizer.zero_grad()	<span class="comment"># 清空梯度</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># metrics</span></span><br><span class="line">        step_metrics = &#123;<span class="variable language_">self</span>.stage+<span class="string">&quot;_&quot;</span>+name:metric_fn(preds, labels).item() </span><br><span class="line">                        <span class="keyword">for</span> name,metric_fn <span class="keyword">in</span> <span class="variable language_">self</span>.metrics_dict.items()&#125;</span><br><span class="line">        <span class="keyword">return</span> loss.item(),step_metrics</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">self,features,labels</span>):</span><br><span class="line">        <span class="variable language_">self</span>.net.train() <span class="comment"># 训练模式, dropout层发生作用</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.step(features,labels)</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @torch.no_grad()</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">eval_step</span>(<span class="params">self,features,labels</span>):</span><br><span class="line">        <span class="variable language_">self</span>.net.<span class="built_in">eval</span>() <span class="comment"># 预测模式, dropout层不发生作用</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.step(features,labels)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self,features,labels</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.stage==<span class="string">&quot;train&quot;</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.train_step(features,labels) </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.eval_step(features,labels)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EpochRunner</span>:	<span class="comment"># 一个epoch(废话)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,steprunner</span>):</span><br><span class="line">        <span class="variable language_">self</span>.steprunner = steprunner</span><br><span class="line">        <span class="variable language_">self</span>.stage = steprunner.stage   </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self,dataloader</span>):</span><br><span class="line">        total_loss,step = <span class="number">0</span>,<span class="number">0</span></span><br><span class="line">        loop = tqdm(<span class="built_in">enumerate</span>(dataloader),total =<span class="built_in">len</span>(dataloader),file = sys.stdout)</span><br><span class="line">        <span class="keyword">for</span> i, batch <span class="keyword">in</span> loop: </span><br><span class="line">            loss, step_metrics = <span class="variable language_">self</span>.steprunner(*batch)</span><br><span class="line">            step_log = <span class="built_in">dict</span>(&#123;<span class="variable language_">self</span>.stage+<span class="string">&quot;_loss&quot;</span>:loss&#125;,**step_metrics)</span><br><span class="line">            total_loss += loss</span><br><span class="line">            step+=<span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> i!=<span class="built_in">len</span>(dataloader)-<span class="number">1</span>:</span><br><span class="line">                loop.set_postfix(**step_log)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                epoch_loss = total_loss/step</span><br><span class="line">                epoch_metrics = &#123;<span class="variable language_">self</span>.stage+<span class="string">&quot;_&quot;</span>+name:metric_fn.compute().item() </span><br><span class="line">                                 <span class="keyword">for</span> name,metric_fn <span class="keyword">in</span> <span class="variable language_">self</span>.steprunner.metrics_dict.items()&#125;</span><br><span class="line">                epoch_log = <span class="built_in">dict</span>(&#123;<span class="variable language_">self</span>.stage+<span class="string">&quot;_loss&quot;</span>:epoch_loss&#125;,**epoch_metrics)</span><br><span class="line">                loop.set_postfix(**epoch_log)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span> name,metric_fn <span class="keyword">in</span> <span class="variable language_">self</span>.steprunner.metrics_dict.items():</span><br><span class="line">                    metric_fn.reset()</span><br><span class="line">        <span class="keyword">return</span> epoch_log</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>(<span class="params">net, optimizer, loss_fn, metrics_dict, </span></span><br><span class="line"><span class="params">                train_data, val_data=<span class="literal">None</span>, </span></span><br><span class="line"><span class="params">                epochs=<span class="number">10</span>, ckpt_path=<span class="string">&#x27;checkpoint.pt&#x27;</span>,</span></span><br><span class="line"><span class="params">                patience=<span class="number">5</span>, monitor=<span class="string">&quot;val_loss&quot;</span>, mode=<span class="string">&quot;min&quot;</span></span>):</span><br><span class="line">    history = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, epochs+<span class="number">1</span>):</span><br><span class="line">        printlog(<span class="string">&quot;Epoch &#123;0&#125; / &#123;1&#125;&quot;</span>.<span class="built_in">format</span>(epoch, epochs))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 1，train -------------------------------------------------  </span></span><br><span class="line">        train_step_runner = StepRunner(net = net,stage=<span class="string">&quot;train&quot;</span>,</span><br><span class="line">                loss_fn = loss_fn,metrics_dict=deepcopy(metrics_dict),</span><br><span class="line">                optimizer = optimizer)</span><br><span class="line">        train_epoch_runner = EpochRunner(train_step_runner)</span><br><span class="line">        train_metrics = train_epoch_runner(train_data)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> name, metric <span class="keyword">in</span> train_metrics.items():</span><br><span class="line">            history[name] = history.get(name, []) + [metric]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2，validate -------------------------------------------------</span></span><br><span class="line">        <span class="keyword">if</span> val_data:</span><br><span class="line">            val_step_runner = StepRunner(net = net,stage=<span class="string">&quot;val&quot;</span>,</span><br><span class="line">                loss_fn = loss_fn,metrics_dict=deepcopy(metrics_dict))</span><br><span class="line">            val_epoch_runner = EpochRunner(val_step_runner)</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                val_metrics = val_epoch_runner(val_data)</span><br><span class="line">            val_metrics[<span class="string">&quot;epoch&quot;</span>] = epoch</span><br><span class="line">            <span class="keyword">for</span> name, metric <span class="keyword">in</span> val_metrics.items():</span><br><span class="line">                history[name] = history.get(name, []) + [metric]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3，early-stopping -------------------------------------------------</span></span><br><span class="line">        arr_scores = history[monitor]</span><br><span class="line">        best_score_idx = np.argmax(arr_scores) <span class="keyword">if</span> mode==<span class="string">&quot;max&quot;</span> <span class="keyword">else</span> np.argmin(arr_scores)</span><br><span class="line">        <span class="keyword">if</span> best_score_idx==<span class="built_in">len</span>(arr_scores)-<span class="number">1</span>:</span><br><span class="line">            torch.save(net.state_dict(),ckpt_path)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; reach best &#123;0&#125; : &#123;1&#125; &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span>.<span class="built_in">format</span>(monitor,</span><br><span class="line">                 arr_scores[best_score_idx]),file=sys.stderr)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(arr_scores)-best_score_idx&gt;patience:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;&lt;&lt;&lt;&lt;&lt;&lt; &#123;&#125; without improvement in &#123;&#125; epoch, early stopping &gt;&gt;&gt;&gt;&gt;&gt;&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">                monitor,patience),file=sys.stderr)</span><br><span class="line">            <span class="keyword">break</span> </span><br><span class="line">        net.load_state_dict(torch.load(ckpt_path,weights_only=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> pd.DataFrame(history)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torchmetrics </span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Accuracy</span>(torchmetrics.Accuracy):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dist_sync_on_step=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(dist_sync_on_step=dist_sync_on_step)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, preds: torch.Tensor, targets: torch.Tensor</span>):</span><br><span class="line">        <span class="built_in">super</span>().update(torch.sigmoid(preds),targets.long())	<span class="comment"># 重写update函数, 用sigmoid把数字压缩到0~1之间</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compute</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>().compute()</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">loss_fn = nn.BCEWithLogitsLoss()</span><br><span class="line">optimizer= torch.optim.Adam(net.parameters(),lr = <span class="number">0.01</span>)</span><br><span class="line">metrics_dict = &#123;<span class="string">&quot;acc&quot;</span>:Accuracy(task=<span class="string">&#x27;binary&#x27;</span>)&#125;</span><br><span class="line"></span><br><span class="line">dfhistory = train_model(net,</span><br><span class="line">    optimizer,</span><br><span class="line">    loss_fn,</span><br><span class="line">    metrics_dict,</span><br><span class="line">    train_data = dl_train,</span><br><span class="line">    val_data= dl_val,</span><br><span class="line">    epochs=<span class="number">10</span>,</span><br><span class="line">    patience=<span class="number">5</span>,</span><br><span class="line">    monitor=<span class="string">&quot;val_acc&quot;</span>, </span><br><span class="line">    mode=<span class="string">&quot;max&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="评估模型">评估模型</h2>
<p>dfhistory如下.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">   train_loss  train_acc  val_loss  val_acc  epoch</span><br><span class="line">0    0.489415     0.7691  0.332821   0.8540      1</span><br><span class="line">1    0.344483     0.8530  0.440991   0.7675      2</span><br><span class="line">2    0.339193     0.8565  0.288581   0.8860      3</span><br><span class="line">3    0.294807     0.8776  0.272804   0.8900      4</span><br><span class="line">4    0.249944     0.8997  0.223067   0.9150      5</span><br><span class="line">5    0.212562     0.9115  0.238513   0.9040      6</span><br><span class="line">6    0.219863     0.9117  0.231890   0.9055      7</span><br><span class="line">7    0.231824     0.9038  0.213779   0.9070      8</span><br><span class="line">8    0.213917     0.9132  0.276232   0.8860      9</span><br><span class="line">9    0.209967     0.9150  0.202512   0.9160     10</span><br></pre></td></tr></table></figure>
<h2 id="使用模型">使用模型</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 预测概率</span></span><br><span class="line">y_pred_probs = predict(net,dl_val)</span><br><span class="line"><span class="comment"># 预测类别</span></span><br><span class="line">y_pred = torch.where(y_pred_probs&gt;<span class="number">0.5</span>,</span><br><span class="line">        torch.ones_like(y_pred_probs),torch.zeros_like(y_pred_probs))</span><br></pre></td></tr></table></figure>
<h2 id="保存模型">保存模型</h2>
<p>建议使用保存参数方式保存模型.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(net.state_dict().keys())</span><br><span class="line"></span><br><span class="line">torch.save(net.state_dict(), <span class="string">&quot;./data/net_parameter.pt&quot;</span>)</span><br><span class="line"></span><br><span class="line">net_clone = Net()</span><br><span class="line">net_clone.load_state_dict(torch.load(<span class="string">&quot;./data/net_parameter.pt&quot;</span>,weights_only=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">predict(net_clone,dl_val)</span><br></pre></td></tr></table></figure>
<p>昨天出去玩了没看, 有上一篇的经验之后似乎理解的东西稍微多一点了.</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/" rel="tag"># 大模型</a>
              <a href="/tags/pytorch/" rel="tag"># pytorch</a>
              <a href="/tags/USTC-MINE/" rel="tag"># USTC-MINE</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/08/eat-pytorch-1/" rel="prev" title="20天狂宴Pytorch-Day1">
                  <i class="fa fa-angle-left"></i> 20天狂宴Pytorch-Day1
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/08/eat-pytorch-3/" rel="next" title="20天狂宴Pytorch-Day3">
                  20天狂宴Pytorch-Day3 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">tianlipa</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

</body>
</html>
